# 实验八

## 实验目的

- 掌握指针的基本概念与用法
- 练习通过指针访问一维数组与二维数组
- 掌握指针作为函数参数的用法
- 掌握指针和数组的高级用法
- 掌握通过指针从函数中返回多个值的方法

## 基础编程

### P8.1 二维数组实用工具

我们已经知道，向函数中传递二维数组主要有以下几种方法：

- 方法1：固定行大小

  ```c
  void fun(int a[][5]); // 传递一个行长度为5的数组
  ```

- 方法2：变长数组（VLA）

  ```c
  void fun(int N, int a[][N]); // 传递一个行长度为N的数组
  ```

- 方法3：转为一维指针

  ```c
  void fun(int *a, int N); // 将二维数组作为一维数组传递
  ```

其中，方法1无法处理不同行长度的数组，方法2并非所有编译器都支持，方法3的兼容性最好但是使用起来比较麻烦。因此，我们希望能够编写一个通用函数，接受一个二维数组中首元素的地址、行下标和列下标、二维数组行长度作为参数，返回对应位置元素的指针。

函数原型如下：

```c
int * loc(int *a, int p, int q, int N); // 返回数组a[][N]中a[p][q]的地址
```

例如，有数组`int a[2][3]={{1,2,3},{4,5,6}}`，则可以这样使用该函数：

```c
*loc(&a[0][0], 1, 0, 3); // 4
*loc(&a[0][0], 0, 2, 3) = 0; // 3 -> 0
```

你的任务是将函数`loc()`编写完整。请使用上面提供的函数原型，不要修改函数名称和参数顺序。**OJ上仅提交该函数。**



## P8.2 大小端序验证

【本题无需提交OJ系统】计算机存储具有多个字节的数据时，有两种存储方式。一种是将较高的位放在较高的地址处，较低的位放在较低的地址处，称为小端序，即“高位高地址，低位低地址”；另一种是将较低的位放在较高的地址处，较高的位放在较低的地址处，称为大端序，即“高位低地址，低位高地址”。

> 示例：一个4字节的整数0x12345678在内存中
>
> ​				低地址 -----------------> 高地址
>
> 大端序：0x12 	0x34	0x56	0x78
>
> 小端序：0x78	0x56	0x34	0x12

请你编写程序，利用指针来检测你的电脑是大端序还是小端序。

【提示】可以利用指针的强制类型转换。**无论在大端序还是小端序的计算机上，指针存储的都是一个对象的最低字节的地址。**建立一个int类型的变量a，并创建一个指向它的指针p，p的值就是是a在内存中最低的字节的地址。如果通过强制类型转换强行让C语言把p解释为一个unsigned char类型（1字节）的整数，那么*p的值就是a在内存中地址最低的那个字节的内容。



## 进阶编程

### AP8.1 排序算法的性能

【本题无需提交OJ】请分别编写冒泡排序和选择排序的函数，对同一个随机数组进行排序（按照升序），并测量排序所消耗的时间，回答下面的问题：

1. 对同样的数组进行排序，一般来说冒泡排序和选择排序哪个快？
2. 随着数组大小的增加，选择排序消耗的时间与数组长度大致有着怎样的比例关系？冒泡排序呢？

#### 输入

请**通过文件输入**一个随机数组。随机数组可以用下面的代码产生：

```c
#include <stdio.h>
#include <stdlib.h>
#include <time.h>

int main() {
	int size=0;
	printf("Random Array Size: ");
	scanf("%d", &size);
	FILE *fp;
	char filename[80];
	sprintf(filename, "data-%d.txt", size);
	fp = fopen(filename, "w");
	srand(time(NULL));
	for(int i=0; i<size; i++) {
		fprintf(fp, "%d ", rand());
	}
	fclose(fp);
	return 0;
}
```

#### 输出

你的代码应该将排序好的数组打印到文件中（文件名自定），并在屏幕上打印出两种排序算法所消耗的时间。除了排序算法之外，你还需要编写一个函数用来验证排序是否成功（即排序后的数组是否真的单调递增）。

#### 提示

测量算法的运行时间，可以使用下面的方法：

```c
#include <time.h> // 测量时间需要使用time.h库

//...
clock_t begin, end; // clock_t是time.h中定义的数据类型
begin = clock(); // 获取操作开始前计时器的值
//需要测量时间的操作
end = clock(); // 获取操作结束后计时器的值
float delta_t = (float) (end - begin) / CLOCKS_PER_SEC; // 计算经过的秒数，CLOCKS_PER_SEC是time.h中定义的常量
```

**注意：老师的PPT上所讲的选择排序有一个简化版本：每次都将最大的元素交换到前面，虽然写起来比较简单，但这样会带来比较多的交换次数。请使用优化版本的选择排序（使用常规方法找到最大元素，每轮只进行一次交换）来进行评测。**



### AP8.2 姓名排序

输入若干个人的姓名（英文），请按照字母表序对它们进行排序并打印。**你只可以使用`<string.h>`中的`strcmp`函数**，**排序需要通过字符串指针来实现**。

【特殊要求】程序中除了声明数组时，**禁止使用数组符号**[]

#### 输入

输入有(N+1)行：

```
N
name1
name2
...
nameN
```

第一行是一个整数$2\leq N \leq 20$，后面N行每行是一个由ASCII字符组成的名字（其中可能含有空格），每个名字长度不大于79个字符。

#### 输出

输出有N行，为按照字母表升序排列的名字。

#### 示例

输入

```
3
David Pumpkin
Alice Fish
Bob Potato
```

输出

```
Alice Fish
Bob Potato
David Pumpkin
```

#### 提示

将所有的输入字符串存放在一个字符串数组（二维字符数组）中，然后建立一个新的一维数组、存放指向每个字符串的指针。然后，对这个新的一维数组进行排序即可。



## 持续设计

### CDP8.1 贪吃蛇

本次实验你需要实现一个完整版的贪吃蛇。相比CDP6.1而言，你需要：

1. 贪吃蛇的长度需要能够随着吃到食物而加长。你可以设定一个上限（同时也是存储蛇每节坐标的数组的上限），例如最多可以长到100节。吃到多少食物增加一节你可以自行定义。贪吃蛇每节的坐标用类似CDP6.1的方法存储在一个数组中。注意新的节应该出现在哪里：

   ```
   正确：
   <-----蛇的前进方向
    @oooooooo
    ooooooooo
   错误：
   <-----蛇的前进方向
     @oooooooo
      ooooooooo
   ```

   

2. 除了食物之外，你还需要在地图上随机生成一些高额奖励，用`$`来表示。如果当前地图上没有奖励，那么每个时间步都以5%的概率生成一个（如果有则不再生成）。奖励具有一定的限时，经过一段时间后自行消失（你可以自定义这个限时）。吃到奖励可以获得5点的分数。

3. （可选）请对蛇的各项操作进行函数封装，尽可能地将对存储蛇坐标的数组的操作拆分为单个的函数。在实验十中我们将实现链表版本的贪吃蛇，合理的封装有助于减少实验十的工作量。如果你的程序所有地方都是直接使用下标来访问蛇的pos数组的，那么很显然实验十你需要将整个程序重写一遍——来自前几年贪吃蛇的教训。

4. （可选）为贪吃蛇增加不同难度的地图，在进入游戏时先打印一个地图选择界面。你还可以增加闯关模式，当蛇的长度达到一定程度后开启下一张地图。这里提供地图数组的**C语言代码**，你可以直接嵌入到你的程序中，或者使用#include的方式导入，也可以自行转换为二进制的文件，再在你的程序中加载。

   贪吃蛇地图下载：[http://home.ustc.edu.cn/~violinwang/ta/c/2023FA/lab/snake_map.zip](http://home.ustc.edu.cn/~violinwang/ta/c/2023FA/lab/snake_map.zip)

   随附的还有用于生成贪吃蛇地图的Matlab程序。如果觉得助教提供的地图不够刺激，你还可以自己绘制一个地图，用Matlab将其转换成对应的C语言代码。（需要安装Matlab）



### CDP8.2 极简教务系统

本次实验你需要增加课程系统的教师端，包括以下功能：

- 教学秘书可以给主讲教师排课、添加或删除课程
- 主讲教师可以查看自己所教授的课程

简单起见，每门课程只有一个主讲教师，每位教师最多只教授一门课程。

首先定义一个结构体来表示课程信息：

```c
struct Course {
    int cID; // 课程编号
    char cname[CSTRLEN]; // 课程名称，CSTRLEN通过宏定义设置
    int teacherID; // 主讲教师的ID
};
```

然后，我们需要一个数组来存储所有的课程，方法类似我们存储用户信息时所做的：

```c
struct Course AllCourse[CNUM]; // CNUM为最大课程上限，通过宏定义设置

int CourseNum; // 存储实际的课程数量
```

在此基础上，你需要实现以下功能：

- 为教学秘书的菜单增加三个功能：新增课程、删除课程、教师排课
  - 新增课程功能：从键盘输入课程编号和课程名称。如果课程编号已经存在，打印出该已存在课程的信息，并询问是否覆盖。如果课程编号不存在，增加一个新的课程，主讲教师的ID应设置为-1。
  - 删除课程功能：从键盘输入课程编号，打印出相应的课程信息并让用户确认是否删除。（此处代码和删除用户相似）
  - 教师排课功能：从键盘输入用户ID，检查该用户是否存在、是否是教师。如果是已存在的教师用户，打印其姓名等信息以供确认。然后从键盘输入待排课的课程编号，打印课程信息以供确认，然后将该教师的ID写入相应课程的teacherID字段。
- 在教师登录后，在其主菜单下方打印其当前教授的课程编号和名称。
- 修改教学秘书的删除用户功能：如果删除的用户是教师，需要确保其未教授任何课程，否则打印其教授的课程信息，取消删除该教师用户，提示需先为此课程重新排课。



### CDP8.3 Alpha Tic-Tac-Toe

在CDP6.3中，我们实现了基于蒙特卡洛树搜索（MCTS）的井字棋AI。但是，这个AI存在着一些问题：

- 如果只看非负的概率，它会在明明能够胜出时选择平局的下法，因为对它来说平局和胜出是一样的；如果只看胜率，则它可能会在有平局下法时“赌一手”，结果在和人对战时输掉。
- 每次模拟随机走子的信息其实可以被重复利用，即收集和学习经验。

针对第一点，我们可以引入“奖励函数”来实现。在MCTS中，我们其实是采用了这样的一个奖励函数（Reward function）：
$$
r(s)=
\begin{cases}
-1, &\mathrm{if}\;s\;\mathrm{失败} \\
0, &\mathrm{else}
\end{cases}
$$
而我们其实可以进一步将它扩展为：
$$
r(s)=
\begin{cases}
-1, &\rm{if\;\mathit{s}\;失败} \\
0, &\rm{if\;\mathit{s}\;平局} \\
1, &\rm{if\;\mathit{s}\;胜利} \\
0, &\rm{else, 比如尚未结束} \\
\end{cases}
$$
而针对第二点，我们可以引入一个学习机制。我们在CDP6.1中介绍过动作价值函数$q(s,a)$，它代表了对状态$s$下采取动作$a$的价值的衡量。具体而言，我们有一个策略$\pi$，它根据状态来选择动作，即$a=\pi(s)$。那么，如果我们在状态$s_t$下选择了动作$a_t$，接下来我们按照策略$\pi$继续执行下去直到终局，最终我们会得到这样的一组经验：
$$
(r_{t+1},s_{t+1},\pi(s_{t+1})),\dots,(r_{T-1},s_{T-1},\pi(s_{T-1})),(r_T,s_T)
$$
其中$r_i=r(s_i)$，为该状态收获的奖励。则$q_\pi(s_t,a_t)$可以表示为：
$$
q_\pi(s_t,a_t)=r_{t+1}+r_{t+2}+\dots+r_T=\sum_{\tau=t+1}^{T}r_\tau
$$
但是，考虑到状态转移有一定的随机性（因为对手下在哪里并不是确定的），所以上面的式子应该加一个数学期望：
$$
q_\pi(s_t,a_t)=\mathbb{E}[r_{t+1}+r_{t+2}+\dots+r_T]=\mathbb{E}\left[\sum_{\tau=t+1}^{T}r_\tau\right]
$$
当你看到数学期望时，应该有一种觉悟——我们可以使用随机采样的方法来估计它。事实上，计算机科学家正是这样做的，这就是强化学习中的蒙特卡洛方法：蒙特卡洛估计。另一方面，我们在CDP6.1中已经了解过，最优策略就是选择$q$值最大的$a$：
$$
\pi(s)=\arg\max_a q(s,a)
$$
加上这样的策略，我们就得到了**蒙特卡洛控制**算法。将整个过程总结如下：

```
蒙特卡洛控制：
	初始化：表q[s][a]={0}, 表count[s][a]={0}
	For i=1,2,...,N: // 循环N轮直到策略收敛
		初始化状态s_0（空棋盘）
		根据策略pi产生经验s_0,a_0,r_1,s_1,a_1,r_2,...,r_T,s_T
		For t=0,1,...,T-1:
			G_t = r_(t+1) + ... + r_T
			q[s_t][a_t] = (q[s_t][a_t] * count[s_t][a_t] + G_t)/(++count[s_t][a_t]) // 求平均
```

这里，我们使用了一个辅助数组count来记录某个状态-动作对被访问的次数，以方便我们计算平均数。

不过，上面的代码还有一点小问题：如果我们纯粹根据$q$值来选择动作，有可能会选择到一些非法的动作（下在已经有棋子的位置）。在MCTS中，我们是手动剔除掉这些动作的，但是在强化学习中，我们其实有更方便的做法：惩罚。修改奖励函数为：
$$
r(s)=
\begin{cases}
-1, &\rm{if\;\mathit{s}\;失败} \\
0, &\rm{if\;\mathit{s}\;平局} \\
1, &\rm{if\;\mathit{s}\;胜利} \\
0, &\rm{if\;尚未结束} \\
-5,&\rm{if\;选择了非法动作（并视为终局）}
\end{cases}
$$
如果策略选择了非法动作，我们施加一个负的奖励，并且认为当前棋局已经结束，直接开始新的一轮棋局。这样在训练过程中，策略会自行学习到哪些动作是非法的，从而避开它。

最后，还有一个容易被忽略的地方：如果我们的策略直接根据$q$来选择动作，有可能会导致有一些$(s,a)$对自始至终都没有被探索过。在这种情况下，我们对$q$的估计其实是不准确的。这一问题常常通过一种叫做$\epsilon$-greedy的策略来缓解：给定一个0~1之间的数$\epsilon$，策略以$\epsilon$的概率选择一个完全随机的动作，以$(1-\epsilon)$的概率根据$q$函数选择一个最优动作。这时我们称这个策略是“软”的。

由于很多同学在MCTS中写的代码十分不具有可扩展性，因此助教为大家重写了本次的代码，但是删去了关键部分。你的任务是：

- 阅读助教给出的代码，掌握其中对指针的使用，理解各个函数的功能
- 在main函数中，补全蒙特卡洛控制的训练代码
- 训练你的AI，尝试不同的训练轮数、$\epsilon$值、奖励函数，观察实验效果
